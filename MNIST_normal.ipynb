{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Kompresja obrazów z użyciem sieci neuronowej  \n",
        "\n",
        "·         Zbiór danych Fashion-MNIST  \n",
        "\n",
        "·         Budujemy sieć neuronową dla kompresji danych, a następnie próbujemy sprawdzić czy sieć jest wstanie rozpoznać (poprawnie skwalifikować) dane z dekodera. Proszę również pokazać że sieć do kompresji można „rozciąć” na układ koder-dekoder. \n",
        "\n",
        "Tworzymy auto-enkoder i w pierwszej kolejności chcemy pokazać zależność błędu pomiędzy wyjściem a wejściem w stosunku do stopnia kompresji, \n",
        "\n",
        "Następnie patrzymy dla jakiś sensownych – wybranych - punktów z powyższej krzywej jak wygląda klasyfikacja danych zakodowanych.        Dla każdego wyniku stosujemy różne miary błędu (ewaluacji) MSE, macierz pomyłek, krzywe ROC,  specyficzność czułość, pole pod ROC itp.  \n",
        "\n",
        "·         Wyniki proszę porównać z istniejącymi w literaturze.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awBQgr7nu_rL",
        "outputId": "e6cbb243-f66b-4172-f56c-ff02b4ad8bcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset shape: (60000, 28, 28) (60000,)\n",
            "Test dataset shape: (10000, 28, 28) (10000,)\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.optimizers import RMSprop,Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Dense, Conv2D, Activation, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
        "\n",
        "# loading dataset\n",
        "(X, Y), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "print(\"Train dataset shape:\", X.shape, Y.shape)\n",
        "print(\"Test dataset shape:\", x_test.shape, y_test.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfJQZZBaOvzr"
      },
      "source": [
        "# Uczenie modelu na oryginalnym zbiorze danych\n",
        "\n",
        "*   Element listy\n",
        "*   Element listy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xub9SWBGOobG"
      },
      "outputs": [],
      "source": [
        "# preprocessing data\n",
        "X = X / 255.0\n",
        "x_test = x_test / 255.0\n",
        "train_size = X.shape[0]\n",
        "test_size = x_test.shape[0]\n",
        "img_shape = X.shape[1]\n",
        "\n",
        "x_train_array = X.reshape(train_size, img_shape, img_shape, 1)\n",
        "x_test_array = x_test.reshape(test_size, img_shape, img_shape, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PdwM5nhlk-9h"
      },
      "outputs": [],
      "source": [
        "# preprocessing lables\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal',      'Shirt',   'Sneaker',  'Bag',   'Ankle boot']\n",
        "num_classes = len(class_names)\n",
        "Y_ohe = tf.keras.utils.to_categorical(Y, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AIY5zDIMk_n2"
      },
      "outputs": [],
      "source": [
        "# prepering for data for training\n",
        "validation = 0.2\n",
        "batch_size = 64\n",
        "num_epochs = 5\n",
        "patience = 10\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_array, Y_ohe, test_size=validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M035gQpkpSCN",
        "outputId": "3c900bcd-ff2f-4047-9fef-56d8b4e25b15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               802944    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 804,554\n",
            "Trainable params: 804,554\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# building model\n",
        "model = tf.keras.Sequential()\n",
        "model.add(Conv2D(32, (3,3), padding='same', input_shape=(28,28, 1)))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation=tf.nn.relu))\n",
        "model.add(Dense(10, activation=tf.nn.softmax))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyP-_OBdzGnU",
        "outputId": "ca0497c3-5f27-4922-936d-a5b2e40e948d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "750/750 [==============================] - 22s 29ms/step - loss: 0.4302 - accuracy: 0.8486 - val_loss: 0.3162 - val_accuracy: 0.8862\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 20s 27ms/step - loss: 0.2887 - accuracy: 0.8952 - val_loss: 0.2885 - val_accuracy: 0.8960\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 21s 28ms/step - loss: 0.2329 - accuracy: 0.9163 - val_loss: 0.2552 - val_accuracy: 0.9078\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 21s 28ms/step - loss: 0.1959 - accuracy: 0.9293 - val_loss: 0.2483 - val_accuracy: 0.9088\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 21s 27ms/step - loss: 0.1668 - accuracy: 0.9398 - val_loss: 0.2419 - val_accuracy: 0.9168\n"
          ]
        }
      ],
      "source": [
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=patience)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.categorical_crossentropy,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "train_model = model.fit( x_train, y_train,\n",
        "                  batch_size=batch_size,\n",
        "                  epochs=num_epochs,\n",
        "                  verbose=1,\n",
        "                  validation_data=(x_val, y_val),\n",
        "                  callbacks=[early_stop])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvUFSU6d3_gX",
        "outputId": "4f92d102-d5e7-467a-ee41-81d3be067eb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2655 - accuracy: 0.9066\n",
            "Test loss: 0.26552459597587585\n",
            "Test accuracy: 0.9065999984741211\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(x_test_array, y_test, steps=math.ceil(10000/32))\n",
        "# checking the test loss and test accuracy\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
